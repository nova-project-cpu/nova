<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>NOVA ‚Äì AI Walking Assistant</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- TensorFlow.js + COCO-SSD for object detection -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <!-- Tesseract.js for OCR (reading books/text) -->
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@5.0.4/dist/tesseract.min.js"></script>

  <style>
    :root {
      --bg: #020617;
      --accent: #22c55e;
      --accent-soft: rgba(34, 197, 94, 0.15);
      --text-main: #f9fafb;
      --text-subtle: #9ca3af;
      --danger: #f97373;
    }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
    }

    body {
      background: radial-gradient(circle at top, #0f172a 0, #020617 45%, #000 100%);
      color: var(--text-main);
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: stretch;
    }

    .app {
      width: 100%;
      max-width: 480px;
      margin: 0 auto;
      display: flex;
      flex-direction: column;
      height: 100vh;
      padding: 12px;
      gap: 10px;
    }

    header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 6px 10px;
      border-radius: 999px;
      background: rgba(15, 23, 42, 0.9);
      box-shadow: 0 20px 40px rgba(0, 0, 0, 0.35);
      backdrop-filter: blur(16px);
    }

    .logo-text {
      display: flex;
      align-items: center;
      gap: 8px;
      font-weight: 700;
      letter-spacing: 0.12em;
      text-transform: uppercase;
    }

    .logo-circle {
      width: 26px;
      height: 26px;
      border-radius: 999px;
      border: 2px solid var(--accent);
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 14px;
    }

    .badge {
      font-size: 11px;
      padding: 3px 8px;
      border-radius: 999px;
      background: rgba(34, 197, 94, 0.12);
      color: var(--accent);
      text-transform: uppercase;
      letter-spacing: 0.08em;
    }

    .main-card {
      flex: 1;
      position: relative;
      border-radius: 24px;
      overflow: hidden;
      background: radial-gradient(circle at 0 0, rgba(34, 197, 94, 0.25), transparent 55%),
                  radial-gradient(circle at 100% 0, rgba(59, 130, 246, 0.18), transparent 55%),
                  #020617;
      border: 1px solid rgba(148, 163, 184, 0.25);
      display: flex;
      flex-direction: column;
    }

    .video-wrapper {
      position: relative;
      flex: 1;
      background: #0b1120;
    }

    video,
    canvas#overlay {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    .status-bar {
      position: absolute;
      bottom: 8px;
      left: 8px;
      right: 8px;
      padding: 6px 9px;
      border-radius: 999px;
      background: rgba(15, 23, 42, 0.92);
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 8px;
      font-size: 11px;
      color: var(--text-subtle);
    }

    .status-bar strong {
      color: var(--text-main);
    }

    .status-dot {
      width: 8px;
      height: 8px;
      border-radius: 999px;
      background: var(--danger);
      box-shadow: 0 0 12px rgba(248, 113, 113, 0.8);
    }

    .status-dot.on {
      background: var(--accent);
      box-shadow: 0 0 12px rgba(34, 197, 94, 0.9);
    }

    .bottom-panel {
      padding: 10px 12px 4px;
      display: flex;
      flex-direction: column;
      gap: 8px;
      background: rgba(15, 23, 42, 0.9);
      border-top: 1px solid rgba(148, 163, 184, 0.3);
      backdrop-filter: blur(18px);
    }

    .mode-row {
      display: flex;
      gap: 8px;
      align-items: center;
      justify-content: space-between;
    }

    .pill {
      font-size: 11px;
      padding: 3px 9px;
      border-radius: 999px;
      background: rgba(15, 23, 42, 0.9);
      border: 1px solid rgba(148, 163, 184, 0.45);
      color: var(--text-subtle);
      display: inline-flex;
      align-items: center;
      gap: 6px;
    }

    .pill span.mode-label {
      color: var(--accent);
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.12em;
    }

    .hint {
      font-size: 11px;
      color: var(--text-subtle);
    }

    .controls-row {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 8px;
      margin-top: 2px;
    }

    button {
      border: none;
      outline: none;
      cursor: pointer;
      border-radius: 999px;
      padding: 10px 8px;
      font-size: 13px;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.08em;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 6px;
      transition: transform 0.08s ease, box-shadow 0.08s ease, background 0.15s ease;
    }

    button:active {
      transform: scale(0.96);
      box-shadow: none;
    }

    .btn-primary {
      background: var(--accent);
      color: #052e16;
      box-shadow: 0 12px 28px rgba(34, 197, 94, 0.55);
    }

    .btn-secondary {
      background: rgba(15, 23, 42, 0.95);
      color: var(--text-main);
      border: 1px solid rgba(148, 163, 184, 0.55);
    }

    .btn-danger {
      background: rgba(127, 29, 29, 0.9);
      color: #fee2e2;
      border: 1px solid rgba(248, 113, 113, 0.9);
    }

    .btn-icon {
      font-size: 16px;
    }

    .log {
      min-height: 32px;
      font-size: 11px;
      color: var(--text-subtle);
    }

    .log strong {
      color: var(--text-main);
    }

    @media (max-height: 640px) {
      .app {
        padding: 6px;
      }
      header {
        padding: 4px 8px;
      }
      .bottom-panel {
        padding: 8px 10px 2px;
      }
      button {
        padding: 8px 6px;
        font-size: 12px;
      }
    }
  </style>
</head>

<body>
  <div class="app">
    <header>
      <div class="logo-text" aria-label="NOVA Assistant">
        <div class="logo-circle">N</div>
        <div>N.O.V.A</div>
      </div>
      <div class="badge" id="speech-status">Voice: ON</div>
    </header>

    <main class="main-card" aria-live="polite">
      <div class="video-wrapper">
        <video id="camera" autoplay playsinline muted></video>
        <canvas id="overlay"></canvas>

        <div class="status-bar">
          <div style="display:flex; align-items:center; gap:6px;">
            <div id="camera-dot" class="status-dot"></div>
            <span id="mode-label"><strong>Object</strong> mode</span>
          </div>
          <div id="distance-status">Waiting for camera‚Ä¶</div>
        </div>
      </div>

      <section class="bottom-panel">
        <div class="mode-row">
          <div class="pill" id="mode-pill">
            <span class="mode-label">OBJECT</span>
            <span id="mode-desc">Walking assistant</span>
          </div>
          <div class="hint">
            Say: <strong>‚Äúobject mode‚Äù</strong> or <strong>‚Äúbook mode‚Äù</strong>
          </div>
        </div>

        <div class="controls-row" aria-label="Main controls">
          <button id="toggle-camera" class="btn-primary">
            <span class="btn-icon">üì∑</span>
            <span>Camera</span>
          </button>
          <button id="read-text-btn" class="btn-secondary">
            <span class="btn-icon">üìñ</span>
            <span>Read</span>
          </button>
          <button id="mute-btn" class="btn-secondary">
            <span class="btn-icon">üîä</span>
            <span>Mute</span>
          </button>
        </div>

        <div class="controls-row">
          <button id="object-mode-btn" class="btn-secondary">
            <span class="btn-icon">üß≠</span>
            <span>Object</span>
          </button>
          <button id="book-mode-btn" class="btn-secondary">
            <span class="btn-icon">üìù</span>
            <span>Book</span>
          </button>
          <button id="stop-speaking-btn" class="btn-danger">
            <span class="btn-icon">‚õî</span>
            <span>Stop</span>
          </button>
        </div>

        <div class="log" id="log" aria-live="polite"></div>
      </section>
    </main>
  </div>

  <script>
    // ------------------------------
    // OLLAMA CONFIG (LLM ASSISTANT)
    // ------------------------------
    const USE_OLLAMA = true; // set to false if you don't want LLM

    // If app + Ollama are on same computer:
    let OLLAMA_URL = "http://localhost:11434/api/generate";

    // Example model: "llama3.2" (change to your installed model)
    const OLLAMA_MODEL = "llama3.2";

    // If you open this page on a phone and Ollama runs on a PC,
    // change OLLAMA_URL to something like:
    // OLLAMA_URL = "http://192.168.0.10:11434/api/generate";

    async function callOllama(systemPrompt, userPrompt) {
      if (!USE_OLLAMA) return null;

      const fullPrompt = `${systemPrompt}\n\nUser:\n${userPrompt}\nAssistant:`;
      try {
        const res = await fetch(OLLAMA_URL, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            model: OLLAMA_MODEL,
            prompt: fullPrompt,
            stream: false
          })
        });

        if (!res.ok) {
          console.warn("Ollama HTTP error:", res.status);
          return null;
        }

        const data = await res.json();
        const text = (data.response || "").trim();
        return text || null;
      } catch (err) {
        console.warn("Ollama request failed:", err);
        return null;
      }
    }

    // ------------------------------
    // GLOBAL STATE
    // ------------------------------
    let video = null;
    let canvas = null;
    let ctx = null;

    let objectModel = null; // COCO-SSD model
    let isCameraOn = false;
    let isDetecting = false;

    let currentMode = "object"; // "object" or "book"
    let speechEnabled = true;
    let lastSpokenSummary = "";
    let lastSpokenTime = 0;

    let recognition = null; // SpeechRecognition instance

    // Camera zoom control
    let videoTrack = null;
    let cameraCapabilities = null;
    let currentZoom = 1;

    const MIN_CONFIDENCE = 0.6;
    const SPEAK_INTERVAL_MS = 3000;

    // For book reading
    const CROP_SCALE = 0.9;  // use most of the frame
    const MAX_OCR_ATTEMPTS = 3;
    const BASE_UPSCALE = 2.0;

    // Auto book reading
    let autoBookScan = false;
    let lastAutoReadText = "";
    let lastAutoReadTime = 0;
    let isBookScanBusy = false;
    let noTextSeenCount = 0;
    const AUTO_SCAN_INTERVAL_MS = 6000;

    // Ollama scene description state
    let ollamaSceneBusy = false;
    let lastOllamaSceneText = "";

    // ------------------------------
    // HELPERS: UI + SPEECH
    // ------------------------------
    function setLog(message) {
      const log = document.getElementById("log");
      log.innerHTML = message;
    }

    function speak(text) {
      if (!speechEnabled) return;
      if (!("speechSynthesis" in window)) {
        console.warn("SpeechSynthesis not supported");
        return;
      }
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = 1;
      utterance.pitch = 1;
      utterance.lang = "en-US";
      window.speechSynthesis.cancel();
      window.speechSynthesis.speak(utterance);
    }

    function updateModeUI() {
      const modeLabel = document.getElementById("mode-label");
      const modePill = document.getElementById("mode-pill");
      const modeDesc = document.getElementById("mode-desc");

      if (currentMode === "object") {
        modeLabel.innerHTML = "<strong>Object</strong> mode";
        modePill.querySelector(".mode-label").textContent = "OBJECT";
        modeDesc.textContent = "Walking assistant";
      } else {
        modeLabel.innerHTML = "<strong>Book</strong> mode";
        modePill.querySelector(".mode-label").textContent = "BOOK";
        modeDesc.textContent = "Auto reading";
      }
    }

    function setCameraStatus(on) {
      const dot = document.getElementById("camera-dot");
      const distanceStatus = document.getElementById("distance-status");
      if (on) {
        dot.classList.add("on");
        distanceStatus.textContent = "Camera active‚Ä¶";
      } else {
        dot.classList.remove("on");
        distanceStatus.textContent = "Camera off.";
      }
    }

    function setSpeechBadge() {
      const badge = document.getElementById("speech-status");
      if (speechEnabled) {
        badge.textContent = "Voice: ON";
        badge.style.backgroundColor = "rgba(34, 197, 94, 0.12)";
        badge.style.color = "#22c55e";
      } else {
        badge.textContent = "Voice: OFF";
        badge.style.backgroundColor = "rgba(148, 163, 184, 0.25)";
        badge.style.color = "#e5e7eb";
      }
    }

    // ------------------------------
    // CAMERA ZOOM HELPERS
    // ------------------------------
    function hasZoomSupport() {
      return (
        videoTrack &&
        cameraCapabilities &&
        typeof cameraCapabilities.zoom === "object"
      );
    }

    function getZoomRange() {
      const z = cameraCapabilities?.zoom || {};
      return {
        min: z.min ?? 1,
        max: z.max ?? 1,
        step: z.step ?? 0.1,
      };
    }

    async function setCameraZoom(newZoom) {
      if (!hasZoomSupport()) return false;
      const { min, max } = getZoomRange();
      const clamped = Math.max(min, Math.min(max, newZoom));
      try {
        await videoTrack.applyConstraints({ advanced: [{ zoom: clamped }] });
        currentZoom = clamped;
        console.log("Camera zoom set to", clamped);
        return true;
      } catch (e) {
        console.warn("Failed to apply zoom constraints:", e);
        return false;
      }
    }

    async function tryIncreaseCameraZoom() {
      if (!hasZoomSupport()) return false;
      const { min, max } = getZoomRange();
      const startZoom = currentZoom || min || 1;
      const step = (max - min) * 0.35 || 0.5;
      let target = startZoom + step;

      if (target > max) target = max;
      if (target <= startZoom + 0.01) return false;

      const ok = await setCameraZoom(target);
      return ok;
    }

    // ------------------------------
    // CAMERA
    // ------------------------------
    async function startCamera() {
      try {
        video = document.getElementById("camera");
        canvas = document.getElementById("overlay");
        ctx = canvas.getContext("2d");

        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: { ideal: "environment" },
            width: { ideal: 1280 },
            height: { ideal: 720 }
          },
          audio: false
        });

        video.srcObject = stream;

        await new Promise((resolve) => {
          video.onloadedmetadata = () => {
            video.play();
            resolve();
          };
        });

        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // Save track and capabilities for zoom
        videoTrack = stream.getVideoTracks()[0] || null;
        if (videoTrack && typeof videoTrack.getCapabilities === "function") {
          try {
            cameraCapabilities = videoTrack.getCapabilities();
            if (cameraCapabilities.zoom) {
              currentZoom =
                cameraCapabilities.zoom.default ??
                cameraCapabilities.zoom.min ??
                1;
              console.log("Camera zoom capabilities:", cameraCapabilities.zoom);
            }
          } catch (e) {
            console.warn("Could not read camera capabilities:", e);
          }
        }

        isCameraOn = true;
        setCameraStatus(true);

        if (objectModel && !isDetecting && currentMode === "object") {
          isDetecting = true;
          detectLoop();
        }

        setLog("<strong>Camera on.</strong> Say ‚Äúobject mode‚Äù or ‚Äúbook mode‚Äù.");
      } catch (err) {
        console.error(err);
        setLog(
          "Could not access camera. Please allow camera permission and run this app from <strong>http://localhost</strong> or <strong>HTTPS</strong> (for example GitHub Pages). Opening the file directly will not work."
        );
        speak("I cannot access the camera. Please check your permissions and how the page is opened.");
      }
    }

    function stopCamera() {
      if (!video || !video.srcObject) return;
      let tracks = video.srcObject.getTracks();
      tracks.forEach((t) => t.stop());
      video.srcObject = null;
      isCameraOn = false;
      isDetecting = false;
      videoTrack = null;
      cameraCapabilities = null;
      currentZoom = 1;
      autoBookScan = false;
      setCameraStatus(false);
      if (ctx && canvas) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      }
      setLog("Camera stopped.");
    }

    // ------------------------------
    // OBJECT DETECTION + DISTANCE
    // ------------------------------
    function estimateDistanceMeters(bbox) {
      const boxHeight = bbox[3];
      const relHeight = boxHeight / canvas.height;

      let label = "";
      let meters = 0;

      if (relHeight > 0.6) {
        label = "very close";
        meters = 0.5;
      } else if (relHeight > 0.4) {
        label = "close";
        meters = 1.0;
      } else if (relHeight > 0.25) {
        label = "medium distance";
        meters = 2.0;
      } else if (relHeight > 0.15) {
        label = "far";
        meters = 3.0;
      } else {
        label = "very far";
        meters = 4.0;
      }

      return { label, meters };
    }

    function drawPredictions(predictions) {
      if (!ctx) return;

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      predictions.forEach((p) => {
        const [x, y, w, h] = p.bbox;
        const { meters } = estimateDistanceMeters(p.bbox);

        ctx.lineWidth = 3;
        ctx.strokeStyle = "rgba(34, 197, 94, 0.9)";
        ctx.fillStyle = "rgba(15, 23, 42, 0.8)";
        ctx.beginPath();
        if (typeof ctx.roundRect === "function") {
          ctx.roundRect(x, y, w, h, 8);
        } else {
          ctx.rect(x, y, w, h);
        }
        ctx.stroke();

        const label = `${p.class} ~${meters.toFixed(1)}m`;
        const textX = x + 6;

        const textWidth = ctx.measureText(label).width + 14;
        const boxY = y - 22 < 0 ? y + 4 : y - 22;

        ctx.fillRect(x, boxY, textWidth, 22);
        ctx.fillStyle = "#e5e7eb";
        ctx.font = "13px system-ui";
        ctx.fillText(label, textX, boxY + 15);
      });
    }

    function maybeSpeakForPredictions(predictions) {
      if (!speechEnabled) return;
      if (!predictions.length) return;

      const now = Date.now();
      if (now - lastSpokenTime < SPEAK_INTERVAL_MS) return;

      const sorted = predictions.slice().sort((a, b) => b.bbox[3] - a.bbox[3]);
      const best = sorted[0];
      const { meters } = estimateDistanceMeters(best.bbox);

      const sentence = `Obstacle ahead: ${best.class}, about ${meters.toFixed(1)} meters in front of you.`;

      if (sentence === lastSpokenSummary) return;

      speak(sentence);
      lastSpokenSummary = sentence;
      lastSpokenTime = now;

      const distanceStatus = document.getElementById("distance-status");
      distanceStatus.textContent = `Nearest: ${best.class} ~${meters.toFixed(1)}m`;
    }

    // ---------- Ollama: smart navigation sentence ----------
    async function smartDescribeSceneWithOllama(predictions) {
      if (!USE_OLLAMA) return;
      if (ollamaSceneBusy) return;
      if (!predictions || !predictions.length) return;
      if (!canvas) return;

      ollamaSceneBusy = true;

      try {
        const width = canvas.width || 1;
        const lines = predictions.map((p) => {
          const [x, y, w, h] = p.bbox;
          const centerX = x + w / 2;
          let where = "center";
          if (centerX < width * 0.33) where = "left";
          else if (centerX > width * 0.66) where = "right";

          const { meters } = estimateDistanceMeters(p.bbox);
          return `${p.class} at about ${meters.toFixed(1)} meters, ${where} side`;
        });

        const sceneText = lines.join("; ");

        if (sceneText === lastOllamaSceneText) {
          ollamaSceneBusy = false;
          return;
        }

        lastOllamaSceneText = sceneText;

        const systemPrompt = `
You are a very short, calm navigation assistant for a blind person.
You get a list of obstacles with distance and side (left/center/right).
Reply with ONE sentence in very simple English.
Mention the safest direction if possible (for example "keep slightly right", "walk straight").
Maximum 20 words.
Do NOT mention lists or meters explicitly, just talk naturally.`;

        const userPrompt = `Detected objects: ${sceneText}`;

        const guidance = await callOllama(systemPrompt, userPrompt);
        if (guidance) {
          speak(guidance);
          const distanceStatus = document.getElementById("distance-status");
          if (distanceStatus) {
            distanceStatus.textContent = guidance;
          }
        }
      } finally {
        setTimeout(() => {
          ollamaSceneBusy = false;
        }, 2000);
      }
    }

    async function detectLoop() {
      if (!isDetecting || !objectModel || !isCameraOn) return;

      try {
        const predictions = await objectModel.detect(video);
        const filtered = predictions.filter((p) => p.score >= MIN_CONFIDENCE);

        if (currentMode === "object") {
          drawPredictions(filtered);

          if (filtered.length) {
            maybeSpeakForPredictions(filtered);
            // NEW: smarter, LLM-based navigation summary
            smartDescribeSceneWithOllama(filtered);
          } else {
            document.getElementById("distance-status").textContent = "No obstacle detected.";
          }
        }
      } catch (err) {
        console.error(err);
      } finally {
        requestAnimationFrame(detectLoop);
      }
    }

    // ------------------------------
    // BOOK MODE GUIDE OVERLAY (for helpers)
    // ------------------------------
    function drawBookGuide() {
      if (!ctx || !canvas) return;

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      const frameW = canvas.width;
      const frameH = canvas.height;

      const cropW = frameW * CROP_SCALE;
      const cropH = frameH * CROP_SCALE;
      const cropX = (frameW - cropW) / 2;
      const cropY = (frameH - cropH) / 2;

      ctx.fillStyle = "rgba(15, 23, 42, 0.45)";
      ctx.fillRect(0, 0, frameW, frameH);

      ctx.clearRect(cropX, cropY, cropW, cropH);

      ctx.lineWidth = 3;
      ctx.strokeStyle = "rgba(34, 197, 94, 0.9)";
      ctx.beginPath();
      if (typeof ctx.roundRect === "function") {
        ctx.roundRect(cropX, cropY, cropW, cropH, 12);
      } else {
        ctx.rect(cropX, cropY, cropW, cropH);
      }
      ctx.stroke();

      ctx.font = "13px system-ui";
      ctx.fillStyle = "#e5e7eb";
      const hint = "Hold phone over the page";
      const textWidth = ctx.measureText(hint).width;
      ctx.fillText(hint, frameW / 2 - textWidth / 2, cropY - 8);
    }

    // ------------------------------
    // BOOK READING (OCR) HELPERS
    // ------------------------------
    async function captureAndRecognizeFrame(upscaleFactor) {
      const frameW = video.videoWidth;
      const frameH = video.videoHeight;

      const cropW = frameW * CROP_SCALE;
      const cropH = frameH * CROP_SCALE;
      const cropX = (frameW - cropW) / 2;
      const cropY = (frameH - cropH) / 2;

      const UPSCALE = upscaleFactor;

      const tempCanvas = document.createElement("canvas");
      tempCanvas.width = cropW * UPSCALE;
      tempCanvas.height = cropH * UPSCALE;
      const tctx = tempCanvas.getContext("2d");

      tctx.drawImage(
        video,
        cropX, cropY, cropW, cropH,
        0, 0, tempCanvas.width, tempCanvas.height
      );

      const imageData = tctx.getImageData(0, 0, tempCanvas.width, tempCanvas.height);
      const data = imageData.data;
      const contrast = 1.3;

      for (let i = 0; i < data.length; i += 4) {
        const r = data[i];
        const g = data[i + 1];
        const b = data[i + 2];

        let gray = 0.299 * r + 0.587 * g + 0.114 * b;
        gray = ((gray - 128) * contrast) + 128;
        if (gray < 0) gray = 0;
        if (gray > 255) gray = 255;

        data[i] = data[i + 1] = data[i + 2] = gray;
      }
      tctx.putImageData(imageData, 0, 0);

      const dataUrl = tempCanvas.toDataURL("image/png");

      const result = await Tesseract.recognize(dataUrl, "eng", {
        logger: (m) => console.log(m),
      });

      const text = (result.data.text || "").trim();
      const confidence = result.data.confidence || 0;

      console.log("OCR result confidence:", confidence, "length:", text.length);

      return { text, confidence };
    }

    // ------------------------------
    // MANUAL BOOK READING (button / "read" command)
    // ------------------------------
    async function readCurrentFrameText(attempt = 1, upscaleFactor = BASE_UPSCALE) {
      if (!isCameraOn || !video || !canvas) {
        setLog("Camera must be on to read text.");
        speak("Please turn on the camera first.");
        return;
      }

      currentMode = "book";
      updateModeUI();
      isDetecting = false;
      if (ctx && canvas) drawBookGuide();

      if (attempt === 1) {
        setLog("Capturing frame and enhancing text‚Ä¶");
        speak("Scanning text. Please hold still.");
      } else {
        setLog(`Enhancing view, attempt ${attempt}‚Ä¶`);
      }

      try {
        const { text, confidence } = await captureAndRecognizeFrame(upscaleFactor);
        const cleaned = text.replace(/\s+/g, " ").trim();

        const goodLength = cleaned.length > 25;
        const goodConfidence = confidence >= 60;

        if (goodLength && goodConfidence) {
          let finalText = cleaned;

          // NEW: clean & simplify with Ollama
          const systemPrompt = `
You correct and simplify text for a blind person.
The input is OCR text and may contain mistakes or broken lines.
1. Fix obvious OCR mistakes.
2. Merge lines into smooth sentences.
3. Use very simple English.
4. Keep important meaning; you can shorten a little if needed.
Output only the improved text, nothing else.`;

          const userPrompt = cleaned;
          const improved = await callOllama(systemPrompt, userPrompt);
          if (improved) {
            finalText = improved.trim();
          }

          setLog(`<strong>Reading:</strong> ${finalText}`);
          speak("Reading text.");
          speak(finalText);
        } else {
          if (attempt < MAX_OCR_ATTEMPTS) {
            if (attempt === 1 && hasZoomSupport()) {
              const zoomed = await tryIncreaseCameraZoom();
              if (zoomed) {
                setLog("Text looks tiny. Zooming the camera in and retrying‚Ä¶");
                speak("Text is tiny. I am zooming in and trying again.");
                await new Promise((res) => setTimeout(res, 600));
                return readCurrentFrameText(attempt + 1, upscaleFactor);
              }
            }
            const newUpscale = upscaleFactor + 1.0;
            setLog("Improving clarity with digital zoom. Trying again‚Ä¶");
            speak("Improving clarity and trying again.");
            return readCurrentFrameText(attempt + 1, newUpscale);
          }

          if (!cleaned.length) {
            setLog("No clear text detected, even after zoom. Try moving closer or improving light.");
            speak("I could not see any clear text, even after zooming. Please move closer or improve the lighting.");
          } else {
            setLog(
              `Text is hard to read clearly (low confidence). Detected: ${cleaned}`
            );
            speak("The text is hard to read clearly. I will still read what I can see.");
            speak(cleaned);
          }
        }
      } catch (err) {
        console.error(err);
        setLog("Error reading text. See console for details.");
        speak("Something went wrong while reading the text.");
      } finally {
        if (currentMode === "object" && objectModel && isCameraOn) {
          isDetecting = true;
          detectLoop();
        } else if (currentMode === "book") {
          if (ctx && canvas) drawBookGuide();
        }
      }
    }

    // ------------------------------
    // AUTO BOOK READING (for blind users)
    // ------------------------------
    async function autoReadLoop() {
      if (!autoBookScan || !isCameraOn || currentMode !== "book") return;

      const now = Date.now();
      if (isBookScanBusy || now - lastAutoReadTime < AUTO_SCAN_INTERVAL_MS) {
        setTimeout(autoReadLoop, 500);
        return;
      }

      isBookScanBusy = true;

      try {
        const { text, confidence } = await captureAndRecognizeFrame(BASE_UPSCALE);
        const cleaned = text.replace(/\s+/g, " ").trim();

        const enoughText = cleaned.length >= 30;
        const goodConfidence = confidence >= 55;

        if (enoughText && goodConfidence) {
          let finalText = cleaned;

          const systemPrompt = `
You are reading a page out loud for a mathemat blind person.
Input is raw OCR of a book page.
1. Fix OCR mistakes.
2. Combine lines into smooth sentences/paragraphs.
3. Use simple, clear English.
4. Keep all important information, but you may slightly shorten very long text.
Output only the improved text.`;

          const userPrompt = cleaned;
          const improved = await callOllama(systemPrompt, userPrompt);
          if (improved) {
            finalText = improved.trim();
          }

          const snippet = finalText.slice(0, 150);
          const lastSnippet = lastAutoReadText;

          const similar =
            lastSnippet &&
            (snippet.includes(lastSnippet.slice(0, 40)) ||
             lastSnippet.includes(snippet.slice(0, 40)));

          if (!similar) {
            lastAutoReadText = snippet;
            noTextSeenCount = 0;
            setLog(`<strong>Auto reading:</strong> ${finalText}`);
            speak("Reading text.");
            speak(finalText);
          }
        } else {
          noTextSeenCount++;
          if (noTextSeenCount === 2) {
            speak("I do not see clear text yet. Slowly move the phone closer to the page.");
          } else if (noTextSeenCount === 4) {
            speak("Try moving to a brighter place and keeping the page flat.");
            noTextSeenCount = 0;
          }
        }
      } catch (err) {
        console.error(err);
      } finally {
        lastAutoReadTime = Date.now();
        isBookScanBusy = false;
        if (autoBookScan && isCameraOn && currentMode === "book") {
          setTimeout(autoReadLoop, 1000);
        }
      }
    }

    // ------------------------------
    // VOICE COMMANDS
    // ------------------------------
    function handleVoiceCommand(rawText) {
      const text = rawText.toLowerCase();
      console.log("Voice command:", text);

      if (text.includes("object mode") || text.includes("walking mode")) {
        autoBookScan = false;
        currentMode = "object";
        updateModeUI();
        setLog("Switched to object mode (walking assistant).");
        speak("Object mode.");
        if (objectModel && isCameraOn && !isDetecting) {
          isDetecting = true;
          detectLoop();
        }
        return;
      }

      if (text.includes("book mode") || text.includes("reading mode")) {
        currentMode = "book";
        updateModeUI();
        isDetecting = false;
        if (ctx && canvas) drawBookGuide();
        setLog("Book mode. Hold the phone above the page. I will auto read.");
        speak("Book mode. Hold the phone above the page. I will automatically read any clear text I can see.");
        autoBookScan = true;
        autoReadLoop();
        return;
      }

      if (text.includes("mute") || text.includes("stop talking")) {
        speechEnabled = false;
        window.speechSynthesis.cancel();
        setSpeechBadge();
        setLog("Voice feedback muted.");
        return;
      }

      if (text.includes("unmute") || text.includes("talk") || text.includes("speak")) {
        speechEnabled = true;
        setSpeechBadge();
        setLog("Voice feedback turned on.");
        speak("Voice feedback is now on.");
        return;
      }

      if (text.includes("read")) {
        readCurrentFrameText();
        return;
      }
    }

    function initVoiceRecognition() {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        console.warn("SpeechRecognition not supported.");
        setLog("Voice commands not supported in this browser.");
        return;
      }

      recognition = new SpeechRecognition();
      recognition.lang = "en-US";
      recognition.continuous = true;
      recognition.interimResults = false;

      recognition.onresult = (event) => {
        const last = event.results[event.results.length - 1];
        if (!last.isFinal) return;
        const transcript = last[0].transcript.trim();
        handleVoiceCommand(transcript);
      };

      recognition.onerror = (e) => {
        console.warn("Speech recognition error:", e.error);
      };

      recognition.onend = () => {
        try {
          recognition.start();
        } catch (e) {
          console.warn("Could not restart recognition:", e);
        }
      };
    }

    // ------------------------------
    // BUTTON HANDLERS
    // ------------------------------
    function initButtons() {
      const toggleCameraBtn = document.getElementById("toggle-camera");
      const readTextBtn = document.getElementById("read-text-btn");
      const muteBtn = document.getElementById("mute-btn");
      const objectModeBtn = document.getElementById("object-mode-btn");
      const bookModeBtn = document.getElementById("book-mode-btn");
      const stopSpeakingBtn = document.getElementById("stop-speaking-btn");

      toggleCameraBtn.addEventListener("click", () => {
        if (isCameraOn) {
          stopCamera();
          toggleCameraBtn.innerHTML = '<span class="btn-icon">üì∑</span><span>Camera</span>';
        } else {
          startCamera();
          toggleCameraBtn.innerHTML = '<span class="btn-icon">‚úÖ</span><span>On</span>';

          if (!recognition) {
            initVoiceRecognition();
          }
          if (recognition) {
            try {
              recognition.start();
              setLog("Voice commands ready. Say ‚Äúobject mode‚Äù or ‚Äúbook mode‚Äù.");
            } catch (err) {
              console.warn("Speech recognition start failed:", err);
            }
          }
        }
      });

      readTextBtn.addEventListener("click", () => {
        currentMode = "book";
        updateModeUI();
        if (ctx && canvas) drawBookGuide();
        readCurrentFrameText();
      });

      muteBtn.addEventListener("click", () => {
        speechEnabled = !speechEnabled;
        setSpeechBadge();
        if (!speechEnabled) {
          window.speechSynthesis.cancel();
          muteBtn.innerHTML = '<span class="btn-icon">üîá</span><span>Muted</span>';
          setLog("Voice feedback muted.");
        } else {
          muteBtn.innerHTML = '<span class="btn-icon">üîä</span><span>Mute</span>';
          setLog("Voice feedback enabled.");
          speak("Voice feedback is now on.");
        }
      });

      objectModeBtn.addEventListener("click", () => {
        autoBookScan = false;
        currentMode = "object";
        updateModeUI();
        if (objectModel && isCameraOn && !isDetecting) {
          isDetecting = true;
          detectLoop();
        }
        setLog("Object mode. I will call out obstacles and distance.");
        speak("Object mode.");
      });

      bookModeBtn.addEventListener("click", () => {
        currentMode = "book";
        updateModeUI();
        isDetecting = false;
        if (ctx && canvas) drawBookGuide();
        setLog("Book mode. Hold the phone above the page. I will auto read.");
        speak("Book mode. Hold the phone above the page. I will automatically read any clear text I can see.");
        autoBookScan = true;
        autoReadLoop();
      });

      stopSpeakingBtn.addEventListener("click", () => {
        window.speechSynthesis.cancel();
        setLog("Stopped speaking current message.");
      });
    }

    // ------------------------------
    // INIT
    // ------------------------------
    async function init() {
      setLog("Loading AI models‚Ä¶ please wait.");
      setSpeechBadge();
      updateModeUI();

      if (!window.isSecureContext && location.hostname !== "localhost") {
        setLog(
          "This page is not in a secure context. Please run from <strong>http://localhost</strong> or <strong>HTTPS</strong> (GitHub Pages). Camera and microphone may not work here."
        );
      }

      try {
        objectModel = await cocoSsd.load();
        setLog("Object detection ready. Turn on the camera to begin.");
        speak("Object detection model is ready.");
      } catch (err) {
        console.error(err);
        setLog("Failed to load object detection model.");
        speak("I could not load the detection model.");
      }

      initButtons();
    }

    window.addEventListener("load", init);
  </script>
</body>
</html>
